{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lile/anaconda3/envs/NLP/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the GoEmotions dataset\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "\n",
    "# GoEmotions emotion labels\n",
    "candidate_labels = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "    \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\",\n",
    "    \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else -1)\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample(examples):\n",
    "    results = classifier(examples[\"text\"], candidate_labels=candidate_labels, multi_label=True, batch_size=10)\n",
    "    predicted_labels = [[label for label, score in zip(result[\"labels\"], result[\"scores\"]) if score > 0.5] for result in results]\n",
    "    return {\"predicted_labels\": predicted_labels}\n",
    "\n",
    "classified_samples = dataset[\"test\"].select(range(100)).map(classify_sample, batched=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.23      0.75      0.35         8\n",
      "     amusement       0.43      0.86      0.57         7\n",
      "         anger       0.12      1.00      0.22         1\n",
      "     annoyance       0.10      0.67      0.17         6\n",
      "      approval       0.08      0.67      0.15         3\n",
      "        caring       0.05      0.67      0.09         3\n",
      "     confusion       0.04      0.67      0.07         3\n",
      "     curiosity       0.10      0.50      0.17         4\n",
      "        desire       0.06      0.50      0.10         2\n",
      "disappointment       0.00      0.00      0.00         1\n",
      "   disapproval       0.14      0.88      0.24         8\n",
      "       disgust       0.00      0.00      0.00         0\n",
      " embarrassment       0.00      0.00      0.00         0\n",
      "    excitement       0.12      1.00      0.22         2\n",
      "          fear       0.50      0.83      0.62         6\n",
      "     gratitude       0.67      0.89      0.76         9\n",
      "         grief       0.00      0.00      0.00         0\n",
      "           joy       0.17      1.00      0.29         2\n",
      "          love       0.67      0.67      0.67         6\n",
      "   nervousness       0.00      0.00      0.00         0\n",
      "      optimism       0.14      0.50      0.22         4\n",
      "         pride       0.00      0.00      0.00         0\n",
      "   realization       0.00      0.00      0.00         2\n",
      "        relief       0.00      0.00      0.00         0\n",
      "       remorse       0.23      1.00      0.38         3\n",
      "       sadness       0.27      0.75      0.40         4\n",
      "      surprise       0.04      1.00      0.07         2\n",
      "       neutral       0.00      0.00      0.00        36\n",
      "\n",
      "     micro avg       0.11      0.52      0.18       122\n",
      "     macro avg       0.15      0.53      0.21       122\n",
      "  weighted avg       0.19      0.52      0.26       122\n",
      "   samples avg       0.10      0.50      0.16       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def binarize_labels(sample):\n",
    "    binary_ground_truth = [1 if i in sample[\"labels\"] else 0 for i in range(len(candidate_labels))]\n",
    "    binary_predictions = [1 if label in sample[\"predicted_labels\"] else 0 for label in candidate_labels]\n",
    "    return {\"binary_ground_truth\": binary_ground_truth, \"binary_predictions\": binary_predictions}\n",
    "\n",
    "# Apply binarization to classified samples\n",
    "binary_data = classified_samples.map(binarize_labels)\n",
    "\n",
    "# Extract binary ground truth and predictions\n",
    "ground_truth = np.array([sample[\"binary_ground_truth\"] for sample in binary_data])\n",
    "predictions = np.array([sample[\"binary_predictions\"] for sample in binary_data])\n",
    "\n",
    "# Calculate precision, recall, F1-score for each label\n",
    "report = classification_report(ground_truth[:100], predictions[:100], target_names=candidate_labels, zero_division=0)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
